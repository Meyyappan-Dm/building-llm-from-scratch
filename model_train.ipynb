{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "011bab4b-85f9-4727-8cda-7dd40cf3171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTTrainer:\n",
    "    def __init__(self, cfg, text=None, batch_size=4, max_length=256, stride=128, device=None):\n",
    "        self.cfg = cfg\n",
    "        self.tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.build_model().to(self.device)\n",
    "        self.train_loader = self.create_loader(text, batch_size, max_length, stride) if text else None\n",
    "\n",
    "    def build_model(self):\n",
    "        class LayerNorm(nn.Module):\n",
    "            def __init__(self, emb_dim):\n",
    "                super().__init__()\n",
    "                self.eps = 1e-5\n",
    "                self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "                self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "            def forward(self, x):\n",
    "                mean = x.mean(dim=-1, keepdim=True)\n",
    "                var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "                return self.scale * (x - mean) / torch.sqrt(var + self.eps) + self.shift\n",
    "\n",
    "        class GELU(nn.Module):\n",
    "            def forward(self, x):\n",
    "                return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * x.pow(3))))\n",
    "\n",
    "        class FeedForward(nn.Module):\n",
    "            def __init__(self, cfg):\n",
    "                super().__init__()\n",
    "                self.net = nn.Sequential(\n",
    "                    nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "                    GELU(),\n",
    "                    nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                return self.net(x)\n",
    "\n",
    "        class MultiHeadAttention(nn.Module):\n",
    "            def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias):\n",
    "                super().__init__()\n",
    "                self.num_heads = num_heads\n",
    "                self.head_dim = d_out // num_heads\n",
    "                self.query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "                self.key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "                self.value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "                self.proj = nn.Linear(d_out, d_out)\n",
    "                self.dropout = nn.Dropout(dropout)\n",
    "                self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "            def forward(self, x):\n",
    "                B, T, _ = x.size()\n",
    "                q = self.query(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "                k = self.key(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "                v = self.value(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "                att = (q @ k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "                mask = self.mask[:T, :T].bool()\n",
    "                att.masked_fill_(mask, float('-inf'))\n",
    "                att = torch.softmax(att, dim=-1)\n",
    "                att = self.dropout(att)\n",
    "                out = (att @ v).transpose(1, 2).contiguous().view(B, T, -1)\n",
    "                return self.proj(out)\n",
    "\n",
    "        class TransformerBlock(nn.Module):\n",
    "            def __init__(self, cfg):\n",
    "                super().__init__()\n",
    "                self.att = MultiHeadAttention(cfg[\"emb_dim\"], cfg[\"emb_dim\"], cfg[\"context_length\"], cfg[\"drop_rate\"], cfg[\"n_heads\"], cfg[\"qkv_bias\"])\n",
    "                self.ff = FeedForward(cfg)\n",
    "                self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "                self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "                self.drop = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = x + self.drop(self.att(self.norm1(x)))\n",
    "                x = x + self.drop(self.ff(self.norm2(x)))\n",
    "                return x\n",
    "\n",
    "        class GPTModel(nn.Module):\n",
    "            def __init__(self, cfg):\n",
    "                super().__init__()\n",
    "                self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "                self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "                self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "                self.blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])] )\n",
    "                self.norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "                self.out = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "            def forward(self, x):\n",
    "                B, T = x.shape\n",
    "                x = self.tok_emb(x) + self.pos_emb(torch.arange(T, device=x.device))\n",
    "                x = self.drop_emb(x)\n",
    "                x = self.blocks(x)\n",
    "                x = self.norm(x)\n",
    "                return self.out(x)\n",
    "\n",
    "        return GPTModel(self.cfg)\n",
    "\n",
    "    def create_loader(self, text, batch_size, max_length, stride, drop_last=True, shuffle=True):\n",
    "        class GPTDataset(Dataset):\n",
    "            def __init__(self, text, tokenizer, max_length, stride):\n",
    "                tokens = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "                self.inputs = [torch.tensor(tokens[i:i+max_length]) for i in range(0, len(tokens)-max_length, stride)]\n",
    "                self.targets = [torch.tensor(tokens[i+1:i+max_length+1]) for i in range(0, len(tokens)-max_length, stride)]\n",
    "\n",
    "            def __len__(self): return len(self.inputs)\n",
    "            def __getitem__(self, i): return self.inputs[i], self.targets[i]\n",
    "\n",
    "        dataset = GPTDataset(text, self.tokenizer, max_length, stride)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    def calc_loss_batch(self, inputs, targets):\n",
    "        inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "        logits = self.model(inputs)\n",
    "        return nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "\n",
    "    def calc_loss_loader(self, loader, num_batches=None):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(loader):\n",
    "                if num_batches and i >= num_batches: break\n",
    "                losses.append(self.calc_loss_batch(x, y).item())\n",
    "        self.model.train()\n",
    "        return sum(losses) / len(losses)\n",
    "\n",
    "    def generate(self, start_text, max_new_tokens=50):\n",
    "        self.model.eval()\n",
    "        idx = torch.tensor(self.tokenizer.encode(start_text)).unsqueeze(0).to(self.device)\n",
    "        context_size = self.cfg[\"context_length\"]\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -context_size:]\n",
    "            logits = self.model(idx_cond)\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "            idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        decoded = self.tokenizer.decode(idx[0].tolist())\n",
    "        self.model.train()\n",
    "        return decoded\n",
    "\n",
    "    def plot_losses(self, epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "        fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "        ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "        ax1.plot(epochs_seen, val_losses, label=\"Validation loss\", linestyle=\"-.\")\n",
    "        ax1.set_xlabel(\"Epochs\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "        ax2 = ax1.twiny()\n",
    "        ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "        ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"loss-plot.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "    def build_dataloaders(self, train_text, val_text, batch_size=4, max_length=256, stride=128, drop_last=True):\n",
    "        self.train_loader = self.create_loader(train_text, batch_size, max_length, stride, drop_last=drop_last, shuffle=True)\n",
    "        self.val_loader = self.create_loader(val_text, batch_size, max_length, stride, drop_last=False, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d7879f-d809-4672-85e3-32f476624c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256,  # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of transformer blocks\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Whether to use bias in QKV projections\n",
    "}\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize only the model (no training data)\n",
    "model = GPTTrainer(cfg=GPT_CONFIG_124M).model\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44dac88c-c6c1-4f65-bbae-c49fec5b9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32aa92c3-84bc-44a8-9acc-f5c62d76d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop to supported context size\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Get logits from the last position\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "        # Append new token\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c68dfbcb-f8a5-4769-ba42-d03735c84dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you sleeves DW Suzâ€‘ractedSpr!. pian reasoning Grenade\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "trainer = GPTTrainer(cfg=GPT_CONFIG_124M)  # this creates an instance\n",
    "token_ids = generate_text_simple(\n",
    "    model = trainer.model,\n",
    "    idx = text_to_token_ids(start_context, trainer.tokenizer).to(trainer.device),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = trainer.cfg[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, trainer.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4db50f1-b186-4c03-805c-9e46a67671cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "266dddcb-8f7f-44f8-940c-2625dd456559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Create overlapping sequences using a sliding window\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,\n",
    "                         shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24080705-0a7c-4f7d-bb2e-c09e22d1a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into training and validation sets\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Create training DataLoader\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Create validation DataLoader\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4d19724-e4c3-4731-9132-7c5aac13a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53d90373-de03-4330-be5d-86a5de408ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee01b244-4ddf-4c13-8d5b-f68b3ee954d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_batch.view(-1))\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            if num_batches is not None and i >= num_batches:\n",
    "                break\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / (i + 1 if i > 0 else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff385a7e-8317-4651-bec0-d714a028f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Model already instantiated\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfaa39a1-274c-496a-bc83-c39e50e9cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer, context_size):\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "        logits = model(input_batch)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_batch.view(-1))\n",
    "        return loss\n",
    "\n",
    "    def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "        total_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "                if num_batches is not None and i >= num_batches:\n",
    "                    break\n",
    "                loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / (i + 1 if i > 0 else 1)\n",
    "\n",
    "    def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        return train_loss, val_loss\n",
    "\n",
    "    def text_to_token_ids(text, tokenizer):\n",
    "        encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "        return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "    def token_ids_to_text(token_ids, tokenizer):\n",
    "        return tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "\n",
    "    def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -context_size:]\n",
    "            with torch.no_grad():\n",
    "                logits = model(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "            idx = torch.cat([idx, next_token], dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "        model.eval()\n",
    "        input_ids = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "        generated = generate_text_simple(model, input_ids, max_new_tokens=50, context_size=context_size)\n",
    "        output_text = token_ids_to_text(generated, tokenizer)\n",
    "        print(\"\\nGenerated Text:\\n\", output_text.replace(\"\\n\", \" \"))\n",
    "        model.train()\n",
    "\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Generate sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e32988e-7d83-4fde-8e41-44578341f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 8.151, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 6.640, Val loss 8.334\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you,,,,,,,,,,,,,,.                                   \n",
      "Ep 2 (Step 000010): Train loss 5.661, Val loss 7.036\n",
      "Ep 2 (Step 000015): Train loss 5.074, Val loss 6.565\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you, and, and, and, and, and, and, and of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the, and, and\n",
      "Ep 3 (Step 000020): Train loss 4.640, Val loss 6.464\n",
      "Ep 3 (Step 000025): Train loss 4.454, Val loss 6.408\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you, and I had\"                                             \n",
      "Ep 4 (Step 000030): Train loss 4.378, Val loss 6.421\n",
      "Ep 4 (Step 000035): Train loss 4.151, Val loss 6.334\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you, and he was aI a Gisburn, and he was a a.                                 \n",
      "Ep 5 (Step 000040): Train loss 3.502, Val loss 6.323\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you know                           \"II me the donkey- it the donkey, and, and I was a it was a little the\n",
      "Ep 6 (Step 000045): Train loss 3.183, Val loss 6.223\n",
      "Ep 6 (Step 000050): Train loss 3.016, Val loss 6.152\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you know it's the donkey.                                            \n",
      "Ep 7 (Step 000055): Train loss 2.562, Val loss 6.171\n",
      "Ep 7 (Step 000060): Train loss 2.277, Val loss 6.191\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you know it was not that I felt--I had the picture.                                     \n",
      "Ep 8 (Step 000065): Train loss 1.881, Val loss 6.184\n",
      "Ep 8 (Step 000070): Train loss 1.520, Val loss 6.185\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you know; and, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"                    \n",
      "Ep 9 (Step 000075): Train loss 1.301, Val loss 6.226\n",
      "Ep 9 (Step 000080): Train loss 0.920, Val loss 6.197\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"Once, when I looked up, I had made him, and threw back the head to look up at the honour being _mine_--because he had always his\n",
      "Ep 10 (Step 000085): Train loss 0.864, Val loss 6.296\n",
      "\n",
      "Generated Text:\n",
      " Every effort moves you?\"  \"Yes--quite insensible to the irony.   \"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize model and move to device\n",
    "trainer = GPTTrainer(cfg=GPT_CONFIG_124M)\n",
    "# Create the model and optimizer\n",
    "model = trainer.model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "# Build your train and val loaders (assumes text_data is already defined)\n",
    "trainer.build_dataloaders(\n",
    "    train_text=train_data,\n",
    "    val_text=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "# Training configuration\n",
    "num_epochs = 10\n",
    "start_context = \"Every effort moves you\"\n",
    "context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=start_context,\n",
    "    tokenizer=tokenizer,\n",
    "    context_size=context_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb8938db-8aee-4f68-a4f6-31c25ccc66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3371966-988a-4a12-aa45-6414c72cc570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c68b31fe-9ff8-4ef6-8590-b17bf800a766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cba9d1b-c205-4224-b87a-c6f09fbc9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Every effort moves you misproject';features nights pulledPC Viol millionsalam\n"
     ]
    }
   ],
   "source": [
    "trainer = GPTTrainer(GPT_CONFIG_124M)\n",
    "start_text = \"Every effort moves you\"\n",
    "\n",
    "token_ids = trainer.generate(\n",
    "    start_text=start_text,\n",
    "    max_new_tokens=10\n",
    ")\n",
    "\n",
    "print(\"Generated text:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a2e0c-00fa-4405-a398-1c6dc5ad3912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
